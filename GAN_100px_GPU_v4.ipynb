{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN_100px_GPU_v4.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"kYV_Iu87A6VW","colab_type":"text"},"source":["# import pkg & get GPU\n"]},{"cell_type":"code","metadata":{"id":"LvqVvWD2c04j","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","from tensorflow.keras import layers\n","\n","\n","import time\n","!pip install -q imageio\n","from IPython import display\n","tf.enable_eager_execution()\n","\n","print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n","tf.test.is_gpu_available(\n","    cuda_only=False,\n","    min_cuda_compute_capability=None\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1o1aM0tWB4d_","colab_type":"text"},"source":["# load data"]},{"cell_type":"code","metadata":{"id":"kpUn9sCTBa75","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BmIX6Jh4CFGl","colab_type":"code","colab":{}},"source":["!unzip drive/My\\ Drive/AFAD.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OM-JrA_WCRZ5","colab_type":"code","colab":{}},"source":["import os\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","\n","dir_data      = \"/content/AFAD\"\n","Ntrain        = 165000 \n","Ntest         = 100\n","nm_imgs       = np.sort(os.listdir(dir_data))\n","## name of the jpg files for training set\n","nm_imgs_train = nm_imgs[:Ntrain]\n","## name of the jpg files for the testing data\n","nm_imgs_test  = nm_imgs[Ntrain:Ntrain + Ntest]\n","img_shape     = (64, 64, 3)\n","\n","def get_npdata(nm_imgs_train):\n","    X_train = []\n","    for i, myid in enumerate(nm_imgs_train):\n","      \n","        image = load_img(dir_data + \"/\" + myid,\n","                         target_size=img_shape[:2])\n","        image = img_to_array(image)/255.0\n","        X_train.append(image)\n","        if i % 10000 == 0:\n","          print(i)\n","    X_train = np.array(X_train)\n","    return(X_train)\n","\n","X_train = get_npdata(nm_imgs_train)\n","print(\"X_train.shape = {}\".format(X_train.shape))\n","\n","X_test  = get_npdata(nm_imgs_test)\n","print(\"X_test.shape = {}\".format(X_test.shape))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4yJo_iNK-XN","colab_type":"code","colab":{}},"source":["BUFFER_SIZE = 165000\n","BATCH_SIZE = 128\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4mXP5J79JD7D","colab_type":"text"},"source":["# Generator\n"]},{"cell_type":"code","metadata":{"id":"Cqqpwgb6tsPz","colab_type":"code","colab":{}},"source":["def make_generator_model():\n","  \n","  model =tf.keras.models.Sequential()\n","  model.add(layers.InputLayer((100,)))\n","  model.add( layers.Dense( 2048, use_bias=False,  input_shape=(100,) )  )\n","  model.add( layers.Dense( 8*8*128, use_bias=False, activation=\"relu\"  ) )\n","  model.add( layers.BatchNormalization( momentum=0.55 ) )\n","  model.add( layers.Reshape((8,8,128)))\n","  model.add(layers.Dropout(0.2))\n","\n","\n","  model.add( layers.Conv2DTranspose(256, (2,2), strides=(2, 2), padding='same',use_bias=False ) )#16\n","  model.add( layers.BatchNormalization( momentum=0.55) )\n","  model.add( layers.LeakyReLU(0.2) )\n","\n","  model.add( layers.Conv2DTranspose(128, (2,2), strides=(2, 2), padding='same', use_bias=False ) )#32\n","  model.add( layers.BatchNormalization( momentum=0.55 ) )\n","  model.add(layers.Dropout(0.2))\n","\n","  model.add( layers.Conv2DTranspose(64, (2,2), strides=(1, 1), padding='same', use_bias=False ) )#32\n","  model.add( layers.BatchNormalization( momentum=0.55 ) )\n","  model.add(layers.Dropout(0.2))\n","\n","  model.add( layers.Conv2DTranspose(64, (2,2), strides=(2, 2), padding='same', use_bias=False ) )# 64\n","  model.add( layers.BatchNormalization( momentum=0.51 ) )\n","  model.add(layers.Dropout(0.3))\n","\n","\n","  model.add( layers.Conv2DTranspose(3, (2,2), strides=(1, 1), padding='same', use_bias=False,  activation='sigmoid') )\n","\n","\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cJj6VjPCVqYx","colab_type":"text"},"source":["# Test generator"]},{"cell_type":"code","metadata":{"id":"ZN2Ml5twVTnX","colab_type":"code","colab":{}},"source":["\n","generator = make_generator_model()\n","generator_optimizer = tf.keras.optimizers.Adam(0.00007,0.5),\n","generator.compile(loss='binary_crossentropy', optimizer =tf.keras.optimizers.Adam(0.00007,0.5))\n","generator.summary()\n","# noise = tf.random.normal([1, 100])\n","# generated_image = generator(noise, training=False)\n","# print(generated_image.numpy())\n","\n","# plt.imshow(generated_image[0, :, :, :].numpy())\n","# print(generated_image[0, :, :, :].numpy().shape)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2BHEq2hC-nOT","colab_type":"text"},"source":[" x# New Section"]},{"cell_type":"code","metadata":{"id":"YyauecWKgNsD","colab_type":"code","colab":{}},"source":["def plot_generated_images(noise,path_save=None,titleadd=\"\"):\n","    imgs = generator.predict(noise)\n","    fig = plt.figure(figsize=(40,10))\n","    for i, img in enumerate(imgs):\n","        ax = fig.add_subplot(1,5,i+1)\n","        ax.imshow(img)\n","    fig.suptitle(\"Generated images \"+titleadd,fontsize=30)\n","    \n","    if path_save is not None:\n","        plt.savefig(path_save,\n","                    bbox_inches='tight',\n","                    pad_inches=0)\n","        plt.close()\n","    else:\n","        plt.show()\n","noise = np.random.normal(0,1,(5,100))\n","# print(noise[0],'wwww',noise[1])\n","plot_generated_images(noise)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zq0TxkHJVua1","colab_type":"code","colab":{}},"source":["def make_discriminator_model():\n","  \n","  model = tf.keras.Sequential()\n","\n","\n","  model.add( layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape= [64,64,3]  ) )\n","  model.add( layers.MaxPooling2D((2, 2), strides=(2,2)) )\n","  # model.add( layers.LeakyReLU(alpha=0.28) )  \n","  model.add(layers.Dropout(0.3))\n","\n","  model.add( layers.Conv2D( 64, (3,3),  activation='relu', padding='same'  ) )\n","  model.add( layers.Conv2D( 64, (3,3),  activation='relu', padding='same' ) )\n","  # model.add( layers.MaxPooling2D((2, 2), strides=(2,2) ))\n","\n","\n","  model.add( layers.Conv2D( 128, (3,3), activation='relu', padding='same'  ) )\n","  model.add( layers.Conv2D( 128, (3,3), activation='relu', padding='same' ) )\n","  model.add(layers.Dropout(0.3))\n","\n","  model.add( layers.Conv2D( 256, (3,3), activation='relu', padding='same'  ) )\n","  model.add( layers.Conv2D( 256, (3,3), activation='relu', padding='same' ) )\n","\n","  model.add( layers.MaxPooling2D((2, 2), strides=(1,1)) )\n","  model.add(layers.Flatten())\n","  model.add(layers.Dense(1,activation='sigmoid'))\n","\n","\n","  # model.add( layers.LeakyReLU(alpha=0.28) )  \n","  # model.add(layers.Dropout(0.3))\n","\n","  # model.add( layers.Conv2D( 256, (3,3), strides = (2,2), padding = 'same' ) )\n","  # model.add( layers.LeakyReLU(alpha=0.28) )  \n","  # model.add(layers.Dropout(0.3)) \n","\n","  # model.add( layers.Conv2D( 512, (3,3), strides = (2,2), padding = 'same' ) )\n","  # model.add( layers.LeakyReLU(alpha=0.28) )  \n","  # model.add(layers.Dropout(0.3))\n","\n","  # model.add(layers.Flatten())\n","  # model.add(layers.Dense(1))\n","\n","  return model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ua2VJKTRrga2","colab_type":"text"},"source":["# Test Discriminater"]},{"cell_type":"code","metadata":{"id":"xMRwHeUfra7f","colab_type":"code","colab":{}},"source":["discriminator = make_discriminator_model()\n","discriminator_optimizer = tf.keras.optimizers.Adam(0.00007,0.5)\n","discriminator.compile(loss= 'binary_crossentropy', optimizer = discriminator_optimizer,metrics   = ['accuracy'])\n","# img = generator(noise)\n","# predict = discriminator(img)\n","# print(predict)\n","discriminator.summary()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rkh_CHOfVif5","colab_type":"text"},"source":["# GAN"]},{"cell_type":"code","metadata":{"id":"CkFK_EhxVlBC","colab_type":"code","colab":{}},"source":["def build_gan(g,d):\n","    model = tf.keras.Sequential()\n","    model.add(g)\n","    d.trainable = False\n","    model.add(d)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cF5A6Y5USkwP","colab_type":"code","outputId":"6559d767-a9e5-4cbc-f2e5-1e9b5ca7b8a7","executionInfo":{"status":"ok","timestamp":1575622887075,"user_tz":-540,"elapsed":5975,"user":{"displayName":"Chen Danny","photoUrl":"","userId":"12826924324839333908"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["gan = build_gan(generator,discriminator)\n","gan.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4))\n","gan.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","sequential (Sequential)      (None, 64, 64, 3)         17328896  \n","_________________________________________________________________\n","sequential_1 (Sequential)    (None, 1)                 1409025   \n","=================================================================\n","Total params: 18,737,921\n","Trainable params: 17,311,488\n","Non-trainable params: 1,426,433\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5sdlQbg9Jupm","colab_type":"code","colab":{}},"source":["\n","discriminator.save_weights('dtmp.h5')\n","generator.save_weights('gtmp.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ceeuPNCkxcyd","colab_type":"text"},"source":["# Train \n"]},{"cell_type":"code","metadata":{"id":"BY08KWxPri9Q","colab_type":"code","colab":{}},"source":["def train(G, D,GAN,epochs,batch_size, start,des_dir ='/content/drive/My Drive/model_history1205'):\n","    generator = G\n","    discriminator = D\n","    gan = GAN\n","    history = list()\n","    for epoch in range(epochs):\n","        Dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder = True)\n","        batch_count = 0\n","        d_loss = (0,0)\n","        g_loss = (0,0)\n","        d_not_train = 0\n","        noise =  np.random.normal(0,1,(batch_size,100))\n","        for batch in Dataset:\n","            # D train\n","            discriminator.trainable = True\n","            fake_images = generator.predict(noise)\n","            d_loss_real = discriminator.train_on_batch(batch, np.ones( (batch_size,1) ))\n","            d_loss_fake = discriminator.train_on_batch(fake_images, np.zeros((batch_size,1)))\n","            d_loss = 0.5*np.add(d_loss_real , d_loss_fake)\n","            # G train\n","            discriminator.trainable = False\n","            generator.trainable = True\n","            noise =  np.random.normal(0,1,(batch_size,100))\n","            valid_y = (np.array([1] * batch_size)).reshape(batch_size,1)\n","            g_loss_batch = gan.train_on_batch(noise,valid_y)\n","            g_loss = np.add(g_loss , g_loss_batch)            \n","            discriminator.trainable = True\n","\n","            # print result\n","            batch_count = batch_count + 1\n","            if (batch_count % 1000) == 0:\n","                fig = plt.figure(figsize=(30,10))\n","                img = generator.predict(noise)\n","                nplot = 4\n","                for count in range(1,nplot):\n","                    ax = fig.add_subplot(1,nplot,count)\n","                    ax.imshow(img[count])\n","                plt.savefig(str(epoch)+'_'+str(batch_count)+'.png')\n","                plt.show()\n","            # save model\n","            if (batch_count % 1000) == 0: \n","                generator.save(des_dir+'/generator＿'+str(start+epoch)+'_'+str(batch_count)+'.h5',include_optimizer = True) \n","                discriminator.save(des_dir+'/discriminator＿'+str(start +epoch)+'_'+str(batch_count)+'.h5',include_optimizer = True) \n","                history.append(d_loss)\n","            if (batch_count % 50) == 0: \n","                print('batch: {}, d_loss: {}'.format(batch_count, d_loss ), d_not_train)\n","\n","            # Epoch end\n","\n","        \n","        # d_loss = d_loss/batch_count\n","        # history.append((epoch,d_loss,g_loss))\n","        print('epoch: {}, d_loss: {}, g_loss: {}'.format(epoch,d_loss,g_loss))\n","        # generator.save(des_dir+'/generator＿'+str(start+epoch)+'.h5',include_optimizer = False) \n","        # discriminator.save(des_dir+'/discriminator＿'+str(start +epoch)+'.h5',include_optimizer = False) \n","\n","    return history\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MwiO0XIVrnVP","colab_type":"code","colab":{}},"source":["history = train(generator, discriminator, gan, 50, BATCH_SIZE,0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"emvUdWfRSv5O","colab_type":"text"},"source":["# Test result"]},{"cell_type":"code","metadata":{"id":"4aEkNsf_Ke1i","colab_type":"code","colab":{}},"source":["# generator = tf.keras.models.load_model('/content/model_history/generator＿4.h5')\n","# discriminator = tf.keras.models.load_model('/content/model_history/discriminator＿4.h5')\n","plot_generated_images(noise)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_ZfhbkMKSqk-","colab_type":"text"},"source":["# LOAD MODEL"]},{"cell_type":"code","metadata":{"id":"2Hq3E7ZsVMRK","colab_type":"code","colab":{}},"source":["# generator = tf.keras.models.load_model('/content/model_history/generator＿5_100.h5')\n","# discriminator = tf.keras.models.load_model('/content/model_history/discriminator＿5_100.h5')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JULmTTlB5Nqt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}